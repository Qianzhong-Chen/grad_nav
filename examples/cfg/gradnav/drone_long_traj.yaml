params:  
  diff_env:
    name: DroneLongTrajEnv
    stochastic_env: True
    episode_length: 600
    MM_caching_frequency: 16

  network:
    actor: ActorStochasticMLP # [ActorStochasticMLP, ActorDeterministicMLP]
    actor_mlp:
      units: [512, 256, 128]
      activation: elu

    critic: CriticMLP
    critic_mlp:
      units: [512, 256, 128]
      activation: elu

  vae:
    kl_weight: 1.0
    encoder_units: [256, 256, 256]
    decoder_units: [32, 64, 128, 256]

  env_hyper:
    SINGLE_VISUAL_INPUT_SIZE: 16
    HISTORY_BUFFER_NUM: 5
    LATENT_VECT_NUM: 24

  config:
    name: drone_long_traj
    map_name: gate_mid # [gate_mid, gate_right]
    actor_learning_rate: 1e-4 # adam
    critic_learning_rate: 1e-4 # adam
    vae_learning_rate: 5e-4
    lr_schedule: cosine # ['constant', 'linear', 'cosine']
    target_critic_alpha: 0.2
    obs_rms: True
    ret_rms: False
    critic_iterations: 16
    critic_method: td-lambda # ['td-lambda', 'one-step']
    lambda: 0.95
    num_batch: 4
    gamma: 0.99
    betas: [0.7, 0.95] # adam
    steps_num: 32
    grad_norm: 1.0
    truncate_grads: True
    num_actors: 128
    save_interval: 50
    max_epochs: 600 # total training iterations
    domain_randomization: True

    # Low Pass Filter
    LPF_train: True
    LPF_val: 0.5

    player:
      determenistic: True
      games_num: 1
      num_actors: 1
      print_stats: True
      LPF_eval: True
      LPF_val: 0.5
